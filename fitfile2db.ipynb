{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FitFile2DB\n",
    "\n",
    "```markdown\n",
    "Author:         Maik 'Schrottie' Bischoff\n",
    "Decription:     Parse Garmin .fit files and write the data to a CSV file or database.\n",
    "Version:        0.6\n",
    "Date:           17.04.2023\n",
    "Requires:       [dtcooper/python-fitparse](https://github.com/dtcooper/python-fitparse)\n",
    "```\n",
    "### Change-/Versionlog:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.6:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Added (simple) error logging function.</li>\n",
    "                <li>Extension of the database with an 'id' field (autoincrement, not null, primary key) and adjustment of the write function because this field does not exist in the dataframe..</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.5:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Added function to use PostgreSQL instead of SQLite3.</li>\n",
    "                <li>Renamed project to FITFILE2DB.\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.4:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Added function to read activity type</lI>\n",
    "                <li>Added function to read the totals of an activity and write them into a table. If some fields of new fit files are missing, the fields would be added to the table.</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.3:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Added function to convert mph to kph</li>\n",
    "                <li>Added a function for write data into database.\n",
    "                    <ul>\n",
    "                        <li>convert some fields to correct datatype</li>\n",
    "                        <li>check whether all fields from the current .fit-file exist in an existing table, if necessary updating the table with the new fields</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.2:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Added a function to recursively search a directory for .fit files to allow processing multiple files at the same time.</li>\n",
    "                <li>Adjusting the field label for the longitude (position_long --> position_lon) so that the field is recognized properly when the data is processed further (e.g. in ArcGIS Pro)</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <span style=\"font-size: 85%;font-family: monospace\">0.1:</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <ul style=\"font-size: 85%;font-family: monospace\">\n",
    "                <li>Basic function for processing a .fit file.</li>\n",
    "                <li>Converting the crude Garmin coordinate format (semicircles) into 'real' coordinates.</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitparse\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "from sqlalchemy.orm import Session\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "fit_path = os.path.join(os.getcwd(), 'testdata')\n",
    "csv_path = os.path.join(os.getcwd(), 'testdata')\n",
    "sqlite_db = os.path.join(os.getcwd(), 'fitfile.db')\n",
    "err_log = os.path.join(os.getcwd(), 'error.log')\n",
    "use_db = True # If True, all data were written into database and no CSV would be generated\n",
    "db_type = \"SQLITE\" # Possible types are 'PGSQL' for PostgreSQL and 'SQLITE' for SQLite3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize error logger\n",
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "date_format = '%d-%b-%y %H:%M:%S'\n",
    "logging.basicConfig(filename=err_log, format=log_format, level=logging.DEBUG, datefmt=date_format)\n",
    "\n",
    "# Configure stream handler for console\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.ERROR)\n",
    "console_handler.setFormatter(logging.Formatter(log_format, datefmt=date_format))\n",
    "\n",
    "# log, log, log ... ;)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "### find_fit_files\n",
    "\n",
    "```markdown\n",
    "Walk through a dir to find files.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fit_files(directory):\n",
    "    try:\n",
    "        fit_files = []\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if is_fit_file(file):\n",
    "                    fit_files.append(os.path.join(root, file))\n",
    "        return fit_files\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in find_fit_files: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_fit_file\n",
    "\n",
    "```markdown\n",
    "Only if it end with fit, it is a fit! ;)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_fit_file(filename):\n",
    "    try:\n",
    "          return filename.lower().endswith('.fit')\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in is_fit_file: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### semicircles_to_degree\n",
    "\n",
    "```markdown\n",
    "Convert crappy Garmin semicircles to useful degrees\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def semicircles_to_degree(semicircles):\n",
    "    try:\n",
    "        return semicircles * (180 / 2 ** 31)\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in semicircles_to_degree: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mph_to_kph\n",
    "\n",
    "```markdown\n",
    "Convert miles per hour to kilometers per hour\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mph_to_kph(speeds):\n",
    "    try:\n",
    "        if speeds is None:\n",
    "            return None\n",
    "        # Convert a single speed value to a list\n",
    "        if isinstance(speeds, (int, float)):\n",
    "            speeds = [speeds]\n",
    "        # Filtering the list to retain only valid speed values\n",
    "        speeds = [s for s in speeds if s is not None and not np.isnan(s)]\n",
    "        # Convert speeds to kph\n",
    "        speeds = [s * 1.609344 for s in speeds]\n",
    "        # Return the first value if it was originally a single value, otherwise return the list\n",
    "        return speeds[0] if len(speeds) == 1 else speeds\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in mph_to_kph: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_env_variables\n",
    "\n",
    "```markdown\n",
    "Load environment variables needed for the db connection\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_variables():\n",
    "    try:\n",
    "        # check if .env-Datei available\n",
    "        if not os.path.isfile('.env'):\n",
    "            raise FileNotFoundError(\"Die .env-Datei wurde nicht gefunden\")\n",
    "\n",
    "        # load env-data from .env\n",
    "        load_dotenv()\n",
    "        host = os.getenv('DB_HOST')\n",
    "        database = os.getenv('DB_NAME')\n",
    "        user = os.getenv('DB_USER')\n",
    "        password = os.getenv('USER_PASSWD')\n",
    "\n",
    "        # check if all variables are available\n",
    "        if not all([server, database, username, password]):\n",
    "            raise ValueError(\"One or more environment variables are missing!\")\n",
    "\n",
    "        return host, database, user, password\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in load_env_variables: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write_to_database\n",
    "\n",
    "```markdown\n",
    "Function to write things into sqlite db\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_database(df, table_name):\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        if db_type == \"PGSQL\":\n",
    "            host, database, user, password = load_env_variables()\n",
    "            conn = psycopg2.connect(host, database, user, password)\n",
    "        elif db_type == \"SQLITE\":\n",
    "            conn = sqlite3.connect(sqlite_db)\n",
    "        else:\n",
    "                return\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Get the columns of the table\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        table_info = cursor.fetchall()\n",
    "        table_columns = [tup[1] for tup in table_info]\n",
    "        \n",
    "        # Add missing columns to the table\n",
    "        for col in df.columns:\n",
    "            if col != 'id' and col not in table_columns:\n",
    "                cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {col} TEXT\")\n",
    "                conn.commit()\n",
    "                table_columns.append(col)\n",
    "                \n",
    "        # Write DataFrame to database\n",
    "        for row in df.itertuples(index=False):\n",
    "            # Create a dictionary mapping column names to their values for the current row\n",
    "            row_dict = {col: getattr(row, col) for col in df.columns}\n",
    "            # Create a list of values in the same order as the columns in the table\n",
    "            values = [row_dict.get(col, '') for col in table_columns if col != 'id']\n",
    "            cursor.execute(f\"INSERT INTO {table_name} ({','.join([col for col in table_columns if col != 'id'])}) VALUES ({','.join(['?']*len(values))})\", tuple(values))\n",
    "            conn.commit()\n",
    "\n",
    "        # Close database connection\n",
    "        conn.close()\n",
    "\n",
    "        print(f\"Data successfully written to table {table_name} in database.\")\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in write_to_database: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_from_database\n",
    "\n",
    "```markdown\n",
    "Function to read some stuff from sqlite db\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_database(query):\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        if db_type == \"PGSQL\":\n",
    "            host, database, user, password = load_env_variables()\n",
    "            conn = psycopg2.connect(host, database, user, password)\n",
    "        elif db_type == \"SQLITE\":\n",
    "            conn = sqlite3.connect(sqlite_db)\n",
    "        else:\n",
    "                return\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        requested_data = pd.read_sql_query(query, conn)\n",
    "\n",
    "        # Close connection and cursor\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        # Return requested data as a Pandas DataFrame\n",
    "        return requested_data\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in read_from_database: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_activity_type\n",
    "\n",
    "```markdown\n",
    "Which type of activity is recorded in actual file?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_type(fit_file):\n",
    "    try:\n",
    "        activity_type = None\n",
    "\n",
    "        # open the file\n",
    "        with fitparse.FitFile(fit_file) as fitfile:\n",
    "\n",
    "            # look for all records with type \"activity\"\n",
    "            for record in fitfile.get_messages(\"activity\"):\n",
    "\n",
    "                # read data field \"sport\" to get activity type\n",
    "                sport_field = record.get(\"sport\")\n",
    "                if sport_field:\n",
    "                    activity_type = sport_field.value\n",
    "\n",
    "        return activity_type\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in get_activity_type: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_totals\n",
    "\n",
    "```markdown\n",
    "Get all totals from fit file and calculate some of them\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_totals(filename):\n",
    "    try:\n",
    "        # Open the fit file\n",
    "        fitfile = fitparse.FitFile(filename)\n",
    "        \n",
    "        # Create an empty list to hold the totals data\n",
    "        totals_data = []\n",
    "\n",
    "        # Loop over all the messages in the FIT file\n",
    "        for record in fitfile.get_messages():\n",
    "            # Check if this is a \"session\" message\n",
    "            if record.name == \"session\":\n",
    "                # Get the activity type\n",
    "                activity_type = record.get_value(\"sport\")\n",
    "\n",
    "                # Create an empty dictionary to hold the totals fields for this message\n",
    "                totals_fields = {\"activity_type\": activity_type}\n",
    "\n",
    "                # Loop over all the fields in this message\n",
    "                for field in record:\n",
    "                    # Check if this field is a \"totals\" field\n",
    "                    if field.name.startswith(\"total_\"):\n",
    "                        # If so, add it to the dictionary\n",
    "                        totals_fields[field.name] = field.value\n",
    "\n",
    "                # Add the totals fields for this message to the list\n",
    "                totals_data.append(totals_fields)\n",
    "\n",
    "        # Create a pandas dataframe from the totals data\n",
    "        df_totals = pd.DataFrame(totals_data)\n",
    "\n",
    "        # Get the base filename without path\n",
    "        filename = os.path.basename(filename)\n",
    "        # Extract the first part of the filename before the first underscore\n",
    "        name_part = filename.split('_')[0]\n",
    "        # Add a new column with the name part of the file name\n",
    "        df_totals.insert(0, \"activity_number\", name_part)\n",
    "\n",
    "        return df_totals\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in get_totals: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_fit_file\n",
    "\n",
    "```markdown\n",
    "Read all data from a single .fit file and write result into pandas dataframe.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fit_file(file_path):\n",
    "    try:\n",
    "        fitfile = fitparse.FitFile(file_path)\n",
    "\n",
    "        data = []\n",
    "        for record in fitfile.get_messages('record'):\n",
    "            # Create an empty dictionary to hold the data for this record\n",
    "            record_data = {}\n",
    "            for data_point in record:\n",
    "                # Convert Garmin-Semicircles to Degree\n",
    "                if data_point.name == 'position_lat' or data_point.name == 'position_long':\n",
    "                    record_data[data_point.name] = semicircles_to_degree(data_point.value)\n",
    "                elif data_point.name == 'radar_speeds':\n",
    "                    record_data[data_point.name] = mph_to_kph(data_point.value)\n",
    "                elif data_point.name == 'passing_speedabs':\n",
    "                    # Include the passing speed in kph directly in the record_data dictionary\n",
    "                    record_data['passing_speed_kph'] = mph_to_kph(data_point.value)\n",
    "                else:\n",
    "                    record_data[data_point.name] = data_point.value\n",
    "\n",
    "            data.append(record_data)\n",
    "\n",
    "        # Convert the list of data to a Pandas DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        # Give the longitude a proper field name\n",
    "        df = df.rename(columns={'position_long': 'position_lon'})\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in read_fit_file: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main-Function: run_fitfile2db\n",
    "\n",
    "```markdown\n",
    "Main function to do all the funny things.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fitfile2db():\n",
    "    try:\n",
    "        # Set the directory to search for .fit files\n",
    "        if fit_path:\n",
    "            directory = fit_path\n",
    "        else:\n",
    "            directory = os.getcwd()\n",
    "\n",
    "        # Find all .fit files in the directory\n",
    "        fit_files = find_fit_files(directory)\n",
    "\n",
    "        # Store filenames in dataframe\n",
    "        df_fn = pd.DataFrame({'filename': fit_files})\n",
    "        fieldname = df_fn.columns[0]\n",
    "        df_fn =df_fn.rename(columns={fieldname: 'filename'})\n",
    "\n",
    "        # Only if db flag is given:\n",
    "        if use_db:\n",
    "            # Check, if filename are known and build a dataframe with new files only\n",
    "            querystring = 'select * from known_fitfiles'\n",
    "            df_known = read_from_database(querystring)\n",
    "            df_fn = df_fn[~df_fn['filename'].isin(df_known['filename'])]\n",
    "            # Exit, if there is no new file\n",
    "            if df_fn.empty:\n",
    "                print('No new files to proceed!')\n",
    "                return\n",
    "        \n",
    "        # Read the data from each (new) .fit file and combine it into a single DataFrame\n",
    "        dfs = []\n",
    "        for fit_file in df_fn['filename']:\n",
    "            df = read_fit_file(fit_file)\n",
    "            dfs.append(df)\n",
    "        combined_df = pd.concat(dfs)\n",
    "\n",
    "        # Convert all fields, except position data, to text\n",
    "        combined_df = combined_df.astype({col: str for col in combined_df.columns if col not in ['position_lat', 'position_lon']})\n",
    "\n",
    "        # Convert position fields to real\n",
    "        if 'position_lat' in combined_df.columns:\n",
    "            combined_df['position_lat'] = pd.to_numeric(combined_df['position_lat'], errors='coerce')\n",
    "        if 'position_lon' in combined_df.columns:\n",
    "            combined_df['position_lon'] = pd.to_numeric(combined_df['position_lon'], errors='coerce')\n",
    "        if 'passing_speed_kph' in combined_df.columns:\n",
    "            combined_df['passing_speed_kph'] = pd.to_numeric(combined_df['passing_speed_kph'], errors='coerce')\n",
    "\n",
    "        # Read the totals from each (new) .fit file and combine it into a single DataFrame\n",
    "        dftotals = []\n",
    "        for fit_file in df_fn['filename']:\n",
    "            dft = get_totals(fit_file)\n",
    "            dftotals.append(dft)\n",
    "        combined_df_totals = pd.concat(dftotals)\n",
    "\n",
    "        # Write the combined DataFrames into database or to a CSV file\n",
    "        if use_db:\n",
    "            write_to_database(combined_df, 'fitfile_data')\n",
    "            write_to_database(combined_df_totals, 'fitfile_totals')\n",
    "            write_to_database(df_fn, 'known_fitfiles')\n",
    "        elif csv_path:\n",
    "            combined_df.to_csv(f'{csv_path}/{today}_output.csv', index=False)\n",
    "            combined_df_totals.to_csv(f'{csv_path}/{today}_output_totals.csv', index=False)\n",
    "        else:\n",
    "            combined_df.to_csv('output.csv', index=False)\n",
    "            combined_df_totals.to_csv('output_totals.csv', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            print(f\"Error in run_fitfile2db: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fitfile2db()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e51ffc48c74bc681f1d405acabe6496ba2a44cafe5d9b8a0bf330bfe99020e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
